# -*- coding: utf-8 -*-
"""ViT_Coin_Classifier_Colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SgPqycUBDAa92LUlTF2oQ9dv-xRFvg5a

# COMP702_Project_ViTs
"""

!pip install timm opencv-python

from google.colab import drive
drive.mount('/content/drive')

"""## Load Dataset"""

DATASET_DIR = "/content/drive/MyDrive/UKZN/COMP702_Project/augmented_coin_dataset_unzipped"

import os
import cv2
import torch
import numpy as np
import pandas as pd
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import LabelEncoder
from timm import create_model
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split

# Constants
DATA_DIR = os.path.join(DATASET_DIR, "augmented_dataset")
CSV_PATH = os.path.join(DATASET_DIR, "coin_labels_augmented.csv")
IMG_SIZE = 224
BATCH_SIZE = 16
EPOCHS = 3
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Load label data
df = pd.read_csv(CSV_PATH)
df['path'] = df['filename'].apply(lambda x: os.path.join(DATA_DIR, x))
label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['denomination'])

# Train-validation split
train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)

# Preprocessing pipeline
def preprocess_image(img_path):
    image = cv2.imread(img_path)
    image = cv2.resize(image, (512, 512))
    sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    sharpened = cv2.filter2D(image, -1, sharpen_kernel)
    gray = cv2.cvtColor(sharpened, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    clahe_applied = clahe.apply(gray)
    normalized = cv2.normalize(clahe_applied, None, 0, 255, cv2.NORM_MINMAX)
    blurred = cv2.GaussianBlur(normalized, (5, 5), 0)
    bilateral = cv2.bilateralFilter(blurred, 9, 75, 75)
    final = cv2.cvtColor(bilateral, cv2.COLOR_GRAY2RGB)
    final = cv2.resize(final, (IMG_SIZE, IMG_SIZE))
    return final

# Dataset class
class CoinDataset(Dataset):
    def __init__(self, dataframe):
        self.dataframe = dataframe
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
        ])
    def __len__(self):
        return len(self.dataframe)
    def __getitem__(self, idx):
        row = self.dataframe.iloc[idx]
        image = preprocess_image(row['path'])
        image = self.transform(image)
        label = row['label']
        return image, label

# Loaders
train_loader = DataLoader(CoinDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(CoinDataset(val_df), batch_size=BATCH_SIZE)

# Model
model = create_model('vit_base_patch16_224', pretrained=True, num_classes=len(label_encoder.classes_))
model.to(DEVICE)

# Training
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

def train_epoch(model, loader):
    model.train()
    running_loss = 0
    for images, labels in loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    return running_loss / len(loader)

def validate(model, loader):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return correct / total

train_losses = []
val_accuracies = []

for epoch in range(EPOCHS):
    train_loss = train_epoch(model, train_loader)
    val_acc = validate(model, val_loader)
    train_losses.append(train_loss)
    val_accuracies.append(val_acc)
    print(f"Epoch {epoch+1}/{EPOCHS} - Loss: {train_loss:.4f} - Val Acc: {val_acc:.4f}")

# Save the model
torch.save(model.state_dict(), "vit_coin_classifier.pth")

# Predict Results
model.eval()
preds, targets = [], []

with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(DEVICE)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        preds.extend(predicted.cpu().numpy())
        targets.extend(labels.numpy())

pred_labels = label_encoder.inverse_transform(preds)
true_labels = label_encoder.inverse_transform(targets)

# Output like X, y = features, denomination
X, y = [], []
for true, pred in zip(true_labels, pred_labels):
    X.append(pred)
    y.append(true)

import numpy as np
X, y = np.array(X), np.array(y)

"""Print Training vs Validation Accuracy"""

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(range(1, EPOCHS+1), val_accuracies, label='Validation Accuracy', marker='o')
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.grid(True)
plt.legend()
plt.show()

"""Get mean cross-validation accuracy"""

from sklearn.model_selection import cross_val_score
from sklearn.base import BaseEstimator, ClassifierMixin

# Wrapper class
class ViTWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, model, device):
        self.model = model
        self.device = device
    def fit(self, X, y):  # Skip fitting (already trained)
        return self
    def predict(self, X):
        self.model.eval()
        preds = []
        with torch.no_grad():
            for image in X:
                image = image.unsqueeze(0).to(self.device)
                output = self.model(image)
                _, pred = torch.max(output, 1)
                preds.append(pred.item())
        return np.array(preds)

# Prepare small subset (due to memory/Colab limits)
subset_loader = DataLoader(CoinDataset(val_df), batch_size=1)
X_val, y_val = [], []

for img, lbl in subset_loader:
    X_val.append(img.squeeze(0))
    y_val.append(lbl.item())

X_val = torch.stack(X_val)
y_val = np.array(y_val)

# Evaluate
vit_clf = ViTWrapper(model, DEVICE)
cv_scores = cross_val_score(vit_clf, X_val, y_val, cv=5)

print(f"Cross-validation scores: {cv_scores}")
print(f"Mean cross-validation accuracy: {cv_scores.mean():.4f}")

from sklearn.metrics import classification_report, accuracy_score

# Print detailed classification report
print("ViTs Classification Report:")
print(classification_report(y, X, target_names=label_encoder.classes_))

# Print accuracy
acc_score = accuracy_score(y, X)
print(f"Accuracy Score: {acc_score:.4f}")
print(f"Accuracy: {acc_score:.2f}")